# Considering papers (projects)

## Submission/evaluation funnel

As we are paying evaluators and have limited funding, we cannot evaluate every paper/project. Through October 2022, **papers have come into our database** (and will continue to do so) through&#x20;

1. Submission by authors
2. Our own searches (e.g., searching syllabi, forums, working paper archives and white papers)
3. Suggestions from other researchers, practitioners, and members of the public (e.g., following [the 'bounty' we posted here](https://forum.effectivealtruism.org/posts/kftzYdmZf4nj2ExN7/what-pivotal-and-useful-research-would-you-like-to-see) and advertised in other places) &#x20;

Our management team **rates the suitability of each paper** according to criteria discussed below and [in the aforementioned linked post](https://forum.effectivealtruism.org/posts/kftzYdmZf4nj2ExN7/what-pivotal-and-useful-research-would-you-like-to-see). \
\
Through October 2022: For the papers/projects at the top of our list, we have contacted the authors and asked if they wanted to engage, and only pursued it further if they agreed.

{% hint style="info" %}
_2 Nov 2022 update_ – We are opening a **second track.** We plan to follow a different procedure for particularly relevant [NBER](https://www.nber.org/papers?page=1\&perPage=50\&sortBy=public\_date) working papers.&#x20;

We will choose the most relevant papers in this prestigious series (in certain categories, and with certain restrictions). We will _inform_ these papers' authors when we have decided to commission these for evaluation. We will give the authors the opportunity to respond and engage, including (as usual) the opportunity to ask for a temporary embargo for sensitive career issues, and the opportunity to respond to the evaluation before it is published. \
\
We discuss this further below, explaining the reasoning behind it. (See [discussion-direct-eval..md](discussion-direct-eval..md "mention"))


{% endhint %}



## Communicating: **‘Editors’ process**&#x20;

_In deciding which papers/projects to send out to paid reviewers/evaluators, we have considered the following issues._&#x20;

_We will try to communicate this information about each paper/project to reviewers before they write their evaluations. We may hold back some discussion to avoid biasing the reviewers or because of discretion issues._

### Summary, why is it relevant and worth engaging with?

**Consider**: Global priority importance ([what-is-ea-gp-relevant-research.md](../../the-field-and-ea-gp-research/what-is-ea-gp-relevant-research.md "mention")), field relevance, open science, authors’ engagement, data and reasoning transparency. You may consider the [ITN framework](https://forum.effectivealtruism.org/topics/itn-framework-1), but not too rigidly. See our [guidelines-for-evaluators](../policies-evaluation/guidelines-for-evaluators/ "mention") for more discussion.

### **Why does it need (more) review, and what are some key issues and claims to vet?**

What are (some of) the authors’ main important claims that are worth carefully evaluating? What aspects of the evidence, argumentation, methods, interpretation, etc., are you unsure about? What particular data, code, proof, etc., would you like to see vetted. If it has already been peer-reviewed in some way, why do you think more review is needed?

### **Author engagement**

How well has the author engaged with the process? Do they need particular convincing? Do they need help making their engagement with The Unjournal successful?

##
