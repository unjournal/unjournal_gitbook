# Evaluation manager process

{% hint style="info" %}
See also [mapping-evaluation-workflow.md](../../policies-projects-evaluation-workflow/mapping-evaluation-workflow.md "mention")for an overview and flowchart of our _full_ process (including the evaluation manager role).&#x20;

_Update Feb. 2024:_ We are moving the discussion of the _details_ of this process to an internal Coda link ([here](https://coda.io/d/The-Unjournal-Hub-internal\_d0KBG3dSZCs/Evaluation-Management\_suhOX#\_luMy4), accessible by team members only). Below, we will only present the overview in broad strokes. \
\
_**Compensation:** As of Dec 2023, evaluation managers are compensated a_ minimum of $300 per project for their work. Further work on 'curating' the evaluation,  engaging further with authors and evaluators, writing detailed evaluation summary content, etc., can earn up to an additional $200.&#x20;
{% endhint %}

## **If you are the evaluation manager please follow the steps below.**&#x20;

### Consult and engage with background information and discussion&#x20;

We keep our internal notes on the paper/project, what merits evaluation etc. in the [Coda space here](https://coda.io/d/The-Unjournal-Hub-internal\_d0KBG3dSZCs/Selected-for-evaluation-being-evaluated\_suyIm#\_luYW7) (team only). Much of this content will be shared with the evaluators (aka 'referees'), giving them guidance on what we are relying on them for, and what they might wish to focus on (which we sometimes call the 'bespoke evaluation notes'). These notes will be later made part of our public output. Other sections in those space are marked as "not shared" and are meant for internal (Unjournal team) discussion only.&#x20;



### Informing or asking paper authors

1. If the work falls under our [direct-evaluation-track.md](../../policies-projects-evaluation-workflow/considering-projects/direct-evaluation-track.md "mention") (NBER+; should be noted in the Airtable), please write to the authors of the paper to let them know that their paper will be evaluated by _The Unjournal_ and ask them about the status of their paper. _In particular, we want to know if the version we are considering is the most recent version._
   * See an example letter template for this [HERE](https://docs.google.com/document/d/1tPgoPpqiuVs9qLKJIwZO71F4kqEfv\_FOL4tDtkm98G0/edit). [Other templates (for this and for other correspondence) are found in our Airtable `text_templates` table.](#user-content-fn-1)[^1]
   * Typically, we advise that you wait five business days to give the authors a chance to respond before directly engaging the evaluators.
2. **Author-submitted work:** Otherwise, if the authors submitted their work to _The Unjournal_ directly, we need to inform them that their work was selected (and make sure all authors are OK with this).

{% hint style="info" %}
_**Note:** Generally, for 'Direct evaluation track' and 'Author-submitted' work,  we ask the Evaluation Managers to contact the authors.  The Unjournal's management may have already done some of the above (before you were assigned as the Evaluation Manager); please check if this is the case._
{% endhint %}

3. **Work requiring '"authors' permission":** Otherwise, if the paper was selected (not submitted), and it _doesn't_ qualify for the Direct Evaluation track (e.g., it is not NBER and/or it has early-career researcher authors) we need to ask the authors' permission to proceed (according to our policies), and of course we also want them to notify us about the paper's status, updates, etc. &#x20;

{% hint style="info" %}
_**Note:**_ Where author permission is required (by our policies), this should generally have been obtaine d by the management team prior to assigning an Evaluation Manager. However, it is worth double-checking that this indeed has been done.&#x20;
{% endhint %}



### Finding and choosing evaluators

Please use the link below to help you consider how to choose evaluators. Normally we commission two evaluators; sometimes we ask for a third evaluation (e.g., where particular expertise is needed). In other cases (e.g., where the paper has become less relevant to evaluate), we may end the process after only a single evaluation.&#x20;

[choosing-evaluators](choosing-evaluators/ "mention")

###

### Reaching out to evaluators

Once you have chosen possible evaluators, you need to reach out to them. A short personalized email seems to get the best response. If you like, you can use or adapt the text templates in the Airtable under the "evaluator" grouping. For example, the "referee outreach (pilot long)" or "short referee outreach (NBER phase)". You often will have to reach out to multiple potential evaluators as they may reject the offer, or not respond.

_Update Nov 2023: We have a system on PubPub that mostly automates the process of queueing invitations, reminders, etc. If you want to try out this system (in alpha) please reach out._  [_See documentation/notes here._](https://notes.knowledgefutures.org/pub/d9vyrdg6/draft?access=c8p3onb0)

Our policy is to send a reminder email five days after the original email. After ten days, if there is still no response, we move on to the next potential evaluator. You can use the "Referee informal followup/reminder" or "PS to referee request" text templates from the Airtable for these emails. (_Dec. 2023: This and_ _other reminders are being automated in our PubPub interface, which is in a preliminary build; we are trying it out now._)

<details>

<summary>Previous automation tools (Nov. 2023: Obsolete soon)</summary>

To speed up the process and automate your reminders, you can use Boomerang, as explained in the following link:

[other-tech-and-tools](../../tech-tools-and-resources/other-tech-and-tools/ "mention")

</details>



If an evaluator agrees,&#x20;

* Send them another email with the Google Doc with the evaluation template for them to complete,&#x20;
* as well as a link to 'Bespoke Evaluation Notes' for this project, if it has been created (see [template](https://docs.google.com/document/d/1IH\_GQYpzu\_v\_Tdq1v-4EiNkb1wENH-4CmYNIoxicd0k/edit#heading=h.twka7svde4w))&#x20;
* Propose a deadline to complete the evaluation; we aim for a three-week turnaround, but we can be somewhat flexible. Make sure we agree on a date.

_Dec. 2023: The new PubPub system has a direct link to the_ evaluation interface.

See also: [protecting-anonymity.md](../../policies-projects-evaluation-workflow/evaluation/protecting-anonymity.md "mention")

### Reminding evaluators

After the agreed time period has elapsed and they have not sent the evaluation, it helps to send a reminder email. This can be short and just direct them to the original email. Our current policy is to send an email on the due date and again five days later. (This will soon be automated in the PubPub system).

### When you receive one evaluation

1. Check through the evaluation and ensure that nothing is missing from the evaluation; reach out to the evaluator for completions and clarifications if necessary.&#x20;
2. If you have no further questions or amendments, you can direct the evaluator to payment information: [fiscal-hosting-and-expenses.md](../fiscal-hosting-and-expenses.md "mention")
3. Wait to receive all the evaluations before proceeding to the next step.

### When you receive all the evaluations

1. Let the evaluators know that you will be sharing the evaluations with the authors. Inform them that their names will not be shared at this stage, but they are free to reach out to the authors. You could use the "letting evaluators know about sharing of evaluations with authors" text template in the Airtable.
2. Share the evaluations with the authors, removing any identifying information about the evaluator. You can compile the evaluations into a single document using our Google Docs template, which we can share with you. You can adapt or modify one of the responses in the Airtable under text\_templates. Perhaps "share\_eval\_with\_authors\_simple" or "Compiled evaluations template -- for author sharing and publication".
3. If the authors say "we won't be able to respond," then let them know we will put it up shortly and proceed. Otherwise, we give them 2 weeks to respond before putting it up (and they can always respond afterwards).
4. Write up an Evaluation Manager's report if you like (this is optional but encouraged; you can get additional compensation for substantial work on a substantive report.).
5. We put all of this up on PubPub, get a DOI,  publicize this, etc. (This process will be partially or fully automated in our updated version of PubPub.
6. Once the evaluations are up on PubPub, you could reach out the evaluators again with the link, in case they want to view their evaluation and the others.&#x20;
   * _The evaluators may be allowed to revise their evaluation, e.g., if the authors find an oversight in the_ evaluation. (We are working on a policy for this.)
   * At the moment (Nov. 2023) we don't have any explicit 'revise and resubmit' procedure, as part of the process. Authors are encouraged to share changes they plan to make, and a (perma)-link to where their revisions can be found. They are also welcome to independently (re)-submit an updated version of their work for a later _Unjournal_ evaluation.&#x20;



[^1]: 3 Feb 2024 -- We are likely to move these templates into PubPub and/or Coda soon, to centralize our content and enable autmation.&#x20;
