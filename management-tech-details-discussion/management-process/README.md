# Evaluation manager process

{% hint style="info" %}
See [mapping-evaluation-workflow.md](../../our-policies-evaluation-and-workflow/mapping-evaluation-workflow.md "mention")for an updated careful overview and flowchart. The material below overlaps that somewhat.\
\
Updated July 4, 2023. Note that the precise implementation of the process below may change as we build [a formal editorial management tool](#user-content-fn-1)[^1].
{% endhint %}

**If you are the evaluation manager please follow the steps below.**

### Informing/asking paper authors

1. If the work falls under our [direct-evaluation-track.md](../../policies-projects-evaluation-workflow/considering-projects/direct-evaluation-track.md "mention") (NBER, may be expanded), please write to the authors of the paper to let them know that their paper will be evaluated by The Unjournal.
   * See an example letter template for this [HERE](https://docs.google.com/document/d/1tPgoPpqiuVs9qLKJIwZO71F4kqEfv\_FOL4tDtkm98G0/edit). Other templates (for this and for other correspondence) are found in our Airtable `text_templates` table.
   * Please wait 5 business days to give the authors a chance to respond before directly engaging evaluators.
2. **Submitted work:** Otherwise, if the authors submitted their work to The Unjournal directly, we need to inform them that their work was selected (and make sure all authors are OK with this.)
3. **Other selected work:** Otherwise, if the paper was selected (not submitted), and it _doesn't_ qualify for the Direct Evaluation track (e.g., it is not NBER and/or it has early-career researcher authors) we need to ask the authors' permission to proceed (according to our policies).

The Unjournal may have already done the above (before you were assigned as the evaluation manager) please check if this is the case.

### Finding evaluators

Please use the link below to help you consider how to choose evaluators. Normally 2-3 evaluators are chosen.

[choosing-evaluators](choosing-evaluators/ "mention")

### Reaching out to evaluators

Once you have chosen possible evaluators, reach out to them. You could possibly use or adapt the text templates in the Airtable under the "evaluator" grouping. For example, the "referee outreach (pilot long)" or "short referee outreach (NBER phase)". It is common that you will have to reach out to multiple potential evaluators as they may reject the offer, or not respond.

Normally, we also send a reminder email roughly two weeks after sending the initial email in case the email has been missed. You could use the "Referee informal followup/reminder" or "PS to referee request" text templates from the Airtable for this. To speed up the process and automate your reminders, you can use Boomerang, this is explained in this link here:

[other-tech-and-tools](../../tech-tools-and-resources/other-tech-and-tools/ "mention")

18 Jun 2023: We are working on a Mailchimp process for this. Later, we are likely to integrate this into our editorial management system (at PubPub or elsewhere).

If an evaluator agrees, send them the google doc with the evaluation template for them to complete in an additional email and agree a time period in which they will complete the evaluation.

(Link to [protecting-anonymity.md](../../policies-projects-evaluation-workflow/evaluation/protecting-anonymity.md "mention"); consider other important pointers to evaluators)

### Reminding evaluators

After the agreed time period has elapsed and they have not sent the evaluation, it may be necessary to send a reminder email. This can be short and just direct them to the original email.

### When you receive one evaluation

1. Check through the evaluation and ensure that nothing is missing from the evaluation or if you have any questions for the evaluation.
2. If you have no further questions or amendments, you can direct the evaluator to payment information:

[fiscal-hosting-and-expenses.md](../fiscal-hosting-and-expenses.md "mention")

3. Wait to receive all the evaluations before proceeding to the next step.

### When you receive all the evaluations

1. Let the evaluators know that you will be sharing the evaluations with the authors. Inform them that their names will not be shared at this stage but they are free to reach out the authors. You could use the "letting evaluators know about sharing of evaluations with authors" text template in the Airtable.
2. Share the evaluations with the authors, removing any identifying information about the evaluator. You can compile the evaluations into a single document using our google doc template which we can share with you. You can adapt or modify one of the responses in the Airtable under text\_templates. Perhaps "share\_eval\_with\_authors\_simple" or "Compiled evaluations template -- for author sharing and publication".
3. If the authors say "we won't be able to respond" then let them know we will put it up shortly and proceed. Otherwise we give them 2 weeks to respond before putting it up (and they can always respond afterwards).
4. Write up an Evaluation Manager's report if you like (this is optional).
5. We put all of this up on PubPub, get a DOI, integrate with Sciety, publicize this, etc.
6. Once the evaluations are up on PubPub, you could reach out the evaluators again with the link, in case they want to view their evaluation and the others.
7. The authors' responses might inform how we engage evaluators. E.g., the authors might
   * Mention a more recent version of the paper we overlooked
   * Request a specific type of feedback we may want to pass on to the evaluators
   * Request an [embargo](../../faq-interaction/for-researchers-authors.md#conditional-embargo)

[^1]: Within PubPub or with another tool. Targeted update: end of Summer 2023.
