# Evaluation (refereeing)

## Evaluation guidelines and criteria

{% hint style="info" %}
[We refer to "evaluation"](#user-content-fn-1)[^1] because _The Unjournal_ does not _publish_ work; it only links, rates, and evaluates it.
{% endhint %}

_For more information about what we are asking evaluators (referees) to do, see:_&#x20;

* [For Prospective Evaluators](../policies-projects-evaluation-workflow/evaluation/for-prospective-evaluators.md)
* [Guidelines for Evaluators](../policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators/)

## Choosing and working with evaluators

### How do we choose evaluators?

* We follow standard procedures, considering complementary expertise, interest, and cross-citations, as well as confirming no conflicts of interest. (See our internal guidelines for [choosing evaluators](../management-tech-details-discussion/management-process/choosing-evaluators/).)
* We aim to consult those who have [opted-in to our evaluator pool](../readme-1/call-for-participants-research/) first.
* We favor evaluators with a track record of careful, in-depth, and insightful evaluation — while giving ECRs a chance to build such a record.

### Why do we pay evaluators?

For several reasons:

* It's equitable, especially for those not getting "service credit" for their refereeing work from their employer.
* Paying evaluators can reduce [adverse selection](#user-content-fn-2)[^2] and conflicts of interest —arguably inherent to the traditional process where reviewers work for free.
* We need to use explicit incentives while _The Unjournal_ grows.
* We can use payment as an incentive for high-quality work, and to access a wider range of expertise, including people not interested in submitting their own work to _The Unjournal_.

<details>

<summary>To claim your evaluator payment...</summary>

[#submitting-and-paying-expenses-claims](../management-tech-details-discussion/fiscal-hosting-and-expenses.md#submitting-and-paying-expenses-claims "mention")

</details>

### **Can I submit an evaluation anonymously? How will you protect my anonymity?**

Yes, we allow evaluators to choose whether they wish to remain anonymous or "sign" their evaluations. See [protecting-anonymity.md](../policies-projects-evaluation-workflow/evaluation/protecting-anonymity.md "mention").

### I'm concerned about making my evaluation public; what if I make a mistake or write something I later regret?

To limit this concern:

1. You can choose to make your evaluation anonymous. You can make this decision from the outset (this is preferable) or later, after you've completed your review.
2. Your evaluation will be shared with the authors before it is posted, and they will be given two weeks to respond before we post. If they cite what they believe are any major misstatements in your evaluation, we will give you the chance to correct these.
3. It is well-known that referee reports and evaluations are subject to mistakes. We expect most people who read your evaluation will take this into account.
4. You can add an addendum or revision to your evaluation later on (see below).

#### Can I redact my evaluation after it's published through The Unjournal?

We will put your evaluation on [PubPub](https://unjournal.pubpub.org) and give it a DOI. It cannot be redacted in the sense that this initial version will remain on the internet in some format. But you can add an addendum to the document later, which we will post and link, and the DOI can be adjusted to point to the revised version.

### Are the research authors involved in The Unjournal's review process and do they give consent?

See the [for-researchers-authors.md](for-researchers-authors.md "mention") FAQ as well as the [direct-evaluation-track.md](../policies-projects-evaluation-workflow/considering-projects/direct-evaluation-track.md "mention").

We have two main ways that papers and research projects enter the _Unjournal_ process:

1. Authors [submit their work](#user-content-fn-3)[^3]; if we believe the work is relevant, we assign evaluators, and so on.
2. We [select research](#user-content-fn-4)[^4] that seems potentially influential, impactful, and relevant for evaluation. In some cases, we request the authors' permission before sending out the papers for evaluation. In other cases (such as where senior authors release papers in the prestigious[ NBER ](https://www.nber.org/papers?page=1\&perPage=50\&sortBy=public\_date)and CEPR series) we contact the authors and request their engagement before proceeding, but we don't ask for permission_._&#x20;

For either track, authors are invited to be involved in several ways:

* Authors are informed of the process and given an opportunity to identify particular concerns, request an embargo, etc.
* Evaluators can be put in touch with authors (anonymously) for clarification questions.
* Authors are given a two-week window to respond to the evaluations (this response is published as well) before the evaluations are made public. They can also respond after the evaluations are released.

### Can I share this evaluation? What else can I do with it?

If you are writing a signed evaluation, you can share it or link it on your own pages. Please wait to do this until _after_ we have given the author a chance to respond and posted the package.

Otherwise, if you are remaining anonymous, please do not disclose your connection to this report.

Going forward:

* We may later invite you to [write and evaluate more about this piece of research](#user-content-fn-5)[^5] . . .
* . . . and to help us judge prizes (e.g., the [impactful-research-prize](../readme-1/call-for-participants-research/impactful-research-prize/ "mention")).
* We may ask if you want to be involved in replication exercises (e.g., through the [Institute for Replication](https://i4replication.org/)).
* As a general principle, we hope and intend always to see that you are fairly compensated for your time and effort.

### **What value do these evaluations provide, and for whom?**

The evaluations provide at least three types of value, helping advance several paths in our [theory of change](../benefits-and-features/global-priorities-theory-of-change/):

1. **For readers and users**: _Unjournal_ evaluations assess the reliability and usefulness of the paper along several dimensions—and make this public, so other researchers and policymakers can [learn from them.](#user-content-fn-6)[^6]
2. **For careers and improving research:** Evaluations provide metrics of quality. In the medium term, these should provide increased and accelerated career value, improving the research process. We aim to build metrics that are credibly comparable to the current "tier" of journal a paper is published in. But we aim to do this better in several ways:
   * More quickly, more reliably, more transparently, and without the unproductive overhead of dealing with journals (see '[reshaping evaluation](../benefits-and-features/costs-of-playing-the-publication-game.md)')
   * Allowing flexible, [transparent formats (such as dynamic documents)](../benefits-and-features/dynamic-documents-vs-living-projects/), thus improving the research process, benefiting research careers, and hopefully improving the research itself in impactful areas.
3. **Feedback and suggestions for authors:** We expect that evaluators will provide feedback that is relevant to the authors, to help them make the paper better.

### What should I prioritize in my evaluation process?

See our [guidelines for evaluators](../policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators/).





[^1]: Still, we sometimes call the evaluators 'referees' for clarity.

[^2]: Traditionally, reviewers may be more likely to accept an assignment when they have a particular interest in the paper under consideration.

[^3]: Sometimes this happens after we reach out to them to suggest they submit it.

[^4]: This occurs both through our internal [prioritization ](../policies-projects-evaluation-workflow/considering-projects/process-prioritizing-research/)process, and through external suggestions, including through our contacts with organizations like [givewell.org](https://givewell.org/) and Open Philanthropy.

[^5]: E.g., for wider audiences, such as on Wikipedia, the EA Forum, or Asterisk magazine, with potential further compensation.

[^6]: They can better understand how to use it, what parts to use, and how much to believe it applies in different contexts, among other insights.
