# Evaluation (refereeing)

{% hint style="info" %}
We refer to 'evaluation' because the Unjournal does not _publish_ work; it only links, rates, and evaluates it. However, below, we will mainly refer to traditional terms like 'referees', indicating the same thing. We do this to make it more readable and familiar.
{% endhint %}

_What we are asking evaluators/referees to do:_ [guidelines-for-evaluators](../../policies-projects-evaluation-workflow/policies-evaluation/guidelines-for-evaluators/ "mention")__

__

## Choosing and working with evaluators (referees)

### How do we choose 'referees'?

* We follow standard procedures, considering complimenatary expertise, interest, cross-citations, and lack of COI
* We aim to consult those who opted-in to our referee pool first



### Why do we pay evaluators?

* It is equitable, especially for those not getting 'service credit'
* While researchers currently write reports for prominent traditional journals for free (perhaps in exchange for goodwill when they submit their own work) we need to use explicit incentives as the Unjournal grows&#x20;
* We can use these as incentives for high-quality work
* We can use payments to access a wider range of expertise, including people not interested in submitting their own work to the Unjournal

## Public evaluations

### How are these hosted and shared?

* [Kotahi](https://kotahi.community/), linked to a [Sciety](https://sciety.org/) group (current plan)
* Also hosted/mirrored on our own page (once we set this up)
* Evaluations will have a DOI, linking these into all relevant systems

## Evaluation guidelines and criteria

### General criteria/guidelines

See [guidelines-for-evaluators](../../policies-projects-evaluation-workflow/policies-evaluation/guidelines-for-evaluators/ "mention") for our proposed approach and template for referees.&#x20;

_Note_ 10 Dec 2022_: This is a  draft approach; we welcome feedback on the best format._

(See also: [#considering-communicating-editors-process](../../policies-projects-evaluation-workflow/considering-projects/#considering-communicating-editors-process "mention"))



## Anonymity/blinding vs. signed reports

_10 Dec 2022:_ Our current policy is to allow evaluators to choose whether they wish to remain anonymous or 'sign their evaluations'

### Feedback and discussion vs. evaluations

> DR: I suspect that signed reviews (cf blog posts) provide good feedback and evaluation. However, when it comes to rating (quantitative measures of a paper's value), my impression from existing initiatives and conversations is that people are reluctant to award anything less than 5/5 'full  marks'.

### Why Single-blind?

* Power dynamics: referees don't want to be 'punished', may want to flatter powerful authors
* Connections and friendships may inhibit honesty
* 'Powerful referees signing critical reports' could hurt ECRs&#x20;

### Why signed reports?

* Public reputation incentive for referees
  * (But note single-blind paid review has some private incentives.)&#x20;
* Fosters better public dialogue
* Inhibits obviously unfair and impolite 'trashing'

### Compromise approaches

* Author and/or referee choose whether it should be single-blind or signed
* Random trial: We can compare empirically (are signed reviews less informative?)
* Use a mix (1 signed, 2 anonymous reviews) for each paper

